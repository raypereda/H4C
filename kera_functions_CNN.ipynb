{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kera-functions-CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raypereda/H4C/blob/master/kera_functions_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "m5qsCKOXqJHm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "0859dec9-fc92-472d-ba5f-f6609157c951"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Activation, MaxPooling2D, Flatten, Dense\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Load MNIST data\n",
        "(x_train, y_train), (x_rest, y_rest) = mnist.load_data()\n",
        "\n",
        "\n",
        "# Data other than training\n",
        "print('Data left for testing',x_rest.shape)\n",
        "\n",
        "\n",
        "#Extracting test and validation data from the remaining data\n",
        "x_val, x_test, y_val, y_test = train_test_split(\n",
        "    x_rest, y_rest, test_size=0.3, random_state=0)\n",
        "\n",
        "\n",
        "print('Validation data shape',x_val.shape)\n",
        "print('Test data shape',x_test.shape)\n",
        "\n",
        "#Use 'Shape' to retrieve number of samples in training, validation and testing\n",
        "\n",
        "train_samples = x_train.shape[0]\n",
        "test_samples = x_test.shape[0]\n",
        "val_samples = x_val.shape[0]\n",
        "\n",
        "#Input reshape. The model expects an input with 4 dimensions.\n",
        "#Reshape your data to (n_images, x_shape, y_shape, n_channels).\n",
        "x_train = x_train.reshape(train_samples,28,28,1)\n",
        "x_val = x_val.reshape(val_samples,28,28,1)\n",
        "x_test = x_test.reshape(test_samples,28,28,1)\n",
        "\n",
        "y_train\n",
        "\n",
        "\n",
        "num_unique_classes = set(y_train)\n",
        "print('Number of unique classes', num_unique_classes)\n",
        "num_classes = len(num_unique_classes)\n",
        "print('Number of classes', num_classes)\n",
        "\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = x_train.shape[1], x_train.shape[2]\n",
        "print('Image width', img_rows)\n",
        "print('Image Height', img_cols)\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train_enc = keras.utils.to_categorical(y_train, num_classes)\n",
        "print('training encoded colums', y_train.shape)\n",
        "y_val_enc = keras.utils.to_categorical(y_val, num_classes)\n",
        "y_test_enc = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(28,28,1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "epochs = 1\n",
        "batch_size = 128\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train_enc,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_val, y_val_enc))\n",
        "\n",
        "pred = model.predict(x_test)\n",
        "\n",
        "\n",
        "predicted=[]\n",
        "for i in pred:\n",
        "    predicted.append(np.argmax(i))\n",
        "    \n",
        "print(\"Test error is:\",100-round(metrics.accuracy_score(y_test,predicted)*100,2))\n",
        "\n",
        "misclassified_sample = []\n",
        "index = 0\n",
        "for actual, predict in zip(y_test, predicted):\n",
        "    if actual != predict:\n",
        "        misclassified_sample.append(index)\n",
        "    index += 1\n",
        "    \n",
        "plt.figure(figsize=(30,5))\n",
        "for index, fail_index in enumerate(misclassified_sample[0:10]):\n",
        "    plt.subplot(1, 10, index + 1)\n",
        "    plt.imshow(np.reshape(x_test[fail_index], (28,28)), cmap='gray')\n",
        "    plt.title('Predicted: {}, Actual: {}'.format(predicted[fail_index], y_test[fail_index]), fontsize = 15)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data left for testing (10000, 28, 28)\n",
            "Validation data shape (7000, 28, 28)\n",
            "Test data shape (3000, 28, 28)\n",
            "Number of unique classes {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
            "Number of classes 10\n",
            "Image width 28\n",
            "Image Height 28\n",
            "training encoded colums (60000,)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 5408)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 50)                270450    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                510       \n",
            "=================================================================\n",
            "Total params: 271,280\n",
            "Trainable params: 271,280\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 7000 samples\n",
            "Epoch 1/1\n",
            "60000/60000 [==============================] - 34s 559us/step - loss: 2.0172 - acc: 0.8298 - val_loss: 0.1187 - val_acc: 0.9650\n",
            "Test error is: 3.299999999999997\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}